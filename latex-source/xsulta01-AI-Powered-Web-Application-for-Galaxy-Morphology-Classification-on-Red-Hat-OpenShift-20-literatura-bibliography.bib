@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@book{timsina2024building,
  title={Building Transformer Models with PyTorch 2.0: NLP, computer vision, and speech processing with PyTorch and Hugging Face (English Edition)},
  author={Timsina, P.},
  isbn={9789355517494},
  url={https://books.google.cz/books?id=7P35EAAAQBAJ},
  year={2024},
  publisher={BPB Publications}
}

@misc{Hickson2016ASTR505,
  author       = {Paul Hickson},
  title        = {{ASTR 505: Galactic Astronomy – Course Notes}},
  howpublished = {Course notes for ASTR 505 (Galactic Astronomy), Department of Physics and Astronomy, The University of British Columbia},
  url          = {https://phas.ubc.ca/~hickson/astr505/astr505_2016.pdf},
  month        = {January},
  year         = {2016},
  note         = {HCG59; NASA/ESA HST; © Paul Hickson},
}

@article{cao2024galaxy,
  title={Galaxy morphology classification based on Convolutional vision Transformer (CvT)},
  author={Cao, Jie and Xu, Tingting and Deng, Yuhe and Deng, Linhua and Yang, Mingcun and Liu, Zhijing and Zhou, Weihong},
  journal={Astronomy \& Astrophysics},
  volume={683},
  pages={A42},
  year={2024},
  publisher={EDP Sciences},
  url={https://www.aanda.org/articles/aa/abs/2024/03/aa48544-23/aa48544-23.html}
}

@misc{Bonham2022Galaxies,
  author       = {Janine Bonham},
  title        = {{Types of Galaxies\,–\,Spiral, Elliptical, Irregular and More}},
  howpublished = {Blog post on \emph{Learn the Sky}},
  url          = {https://www.learnthesky.com/blog/types_of_galaxies},
  year         = {2022},
  month        = apr,
  day          = {2},
  note         = {Accessed: 4 March 2025},
}

@book{van1998galaxy,
  title={Galaxy Morphology and Classification},
  author={Van den Bergh, S.},
  isbn={9780521623353},
  lccn={b98031198},
  url={https://books.google.cz/books?id=geEVkpueEPcC},
  year={1998},
  publisher={Cambridge University Press}
}

@article{Li_2023,
   title={Galaxy morphology classification using multiscale convolution capsule network},
   volume={523},
   ISSN={1365-2966},
   url={http://dx.doi.org/10.1093/mnras/stad854},
   DOI={10.1093/mnras/stad854},
   number={1},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Li, Guangping and Xu, Tingting and Li, Liping and Gao, Xianjun and Liu, Zhijing and Cao, Jie and Yang, Mingcun and Zhou, Weihong},
   year={2023},
   month=may, pages={488–497}, 
}

@article{Hausen_2020,
   title={Morpheus: A Deep Learning Framework for the Pixel-level Analysis of Astronomical Image Data},
   volume={248},
   ISSN={1538-4365},
   url={http://dx.doi.org/10.3847/1538-4365/ab8868},
   DOI={10.3847/1538-4365/ab8868},
   number={1},
   journal={The Astrophysical Journal Supplement Series},
   publisher={American Astronomical Society},
   author={Hausen, Ryan and Robertson, Brant E.},
   year={2020},
   month=may, pages={20} 
}

@misc{walmsley2024scalinglawsgalaxyimages,
      title={Scaling Laws for Galaxy Images}, 
      author={Mike Walmsley and Micah Bowles and Anna M. M. Scaife and Jason Shingirai Makechemu and Alexander J. Gordon and Annette M. N. Ferguson and Robert G. Mann and James Pearson and Jürgen J. Popp and Jo Bovy and Josh Speagle and Hugh Dickinson and Lucy Fortson and Tobias Géron and Sandor Kruk and Chris J. Lintott and Kameswara Mantha and Devina Mohan and David O'Ryan and Inigo V. Slijepevic},
      year={2024},
      eprint={2404.02973},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.02973}, 
}

@misc{song2024usmorphupdatedframeworkautomatic,
      title={USmorph: An Updated Framework of Automatic Classification of Galaxy Morphologies and Its Application to Galaxies in the COSMOS Field}, 
      author={Jie Song and GuanWen Fang and Shuo Ba and Zesen Lin and Yizhou Gu and Chichun Zhou and Tao Wang and Cai-Na Hao and Guilin Liu and Hongxin Zhang and Yao Yao and Xu Kong},
      year={2024},
      eprint={2404.15701},
      archivePrefix={arXiv},
      primaryClass={astro-ph.GA},
      url={https://arxiv.org/abs/2404.15701}, 
}

@book{ayyadevara2024modern,
  title={Modern Computer Vision with PyTorch: A practical roadmap from deep learning fundamentals to advanced applications and Generative AI},
  author={Ayyadevara, V.K. and Reddy, Y.},
  isbn={9781803240930},
  url={https://books.google.cz/books?id=_LUMEQAAQBAJ},
  year={2024},
  publisher={Packt Publishing}
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{wang2021crossformerversatilevisiontransformer,
      title={CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention}, 
      author={Wenxiao Wang and Lu Yao and Long Chen and Binbin Lin and Deng Cai and Xiaofei He and Wei Liu},
      year={2021},
      eprint={2108.00154},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2108.00154}, 
}

@techreport{manning2020ai,
  author       = {Manning, Christopher D.},
  title        = {{AI Definitions}},
  institution  = {Stanford Institute for Human-Centered Artificial Intelligence},
  month        = sep,
  year         = {2020},
  url          = {https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf},
}

@article{Willett_2013,
   title={Galaxy Zoo 2: detailed morphological classifications for 304122 galaxies from the Sloan Digital Sky Survey},
   volume={435},
   ISSN={0035-8711},
   url={http://dx.doi.org/10.1093/mnras/stt1458},
   DOI={10.1093/mnras/stt1458},
   number={4},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Willett, Kyle W. and Lintott, Chris J. and Bamford, Steven P. and Masters, Karen L. and Simmons, Brooke D. and Casteels, Kevin R. V. and Edmondson, Edward M. and Fortson, Lucy F. and Kaviraj, Sugata and Keel, William C. and Melvin, Thomas and Nichol, Robert C. and Raddick, M. Jordan and Schawinski, Kevin and Simpson, Robert J. and Skibba, Ramin A. and Smith, Arfon M. and Thomas, Daniel},
   year={2013},
   month=sep, pages={2835–2860} }

@book{siddiqui2025mastering,
  title={Mastering Computer Vision with PyTorch 2.0: Discover, Design, and Build Cutting-Edge High Performance Computer Vision Solutions with PyTorch 2.0 and Deep Learning Techniques (English Edition)},
  author={Siddiqui, M.A.},
  isbn={9789348107084},
  url={https://books.google.cz/books?id=8Wk_EQAAQBAJ},
  year={2025},
  publisher={Amazon Digital Services LLC-Kdp}
}

@misc{lin2022galaxymorphologicalclassificationefficient,
      title={Galaxy Morphological Classification with Efficient Vision Transformer}, 
      author={Joshua Yao-Yu Lin and Song-Mao Liao and Hung-Jin Huang and Wei-Ting Kuo and Olivia Hsuan-Min Ou},
      year={2022},
      eprint={2110.01024},
      archivePrefix={arXiv},
      primaryClass={astro-ph.GA},
      url={https://arxiv.org/abs/2110.01024}, 
}

@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}


@book{lecun2023when,
  author    = {Yann LeCun},
  title     = {When Machines Learn: The Revolution of Artificial Neurons and Deep Learning},
  isbn={9785907470552},
  url={https://books.google.cz/books?id=1XpGEAAAQBAJ},
  year={2023},
  publisher={Alpina Publisher},
  language  = {Russion}
}

@misc{shao2022adversarialrobustnessvisiontransformers,
      title={On the Adversarial Robustness of Vision Transformers}, 
      author={Rulin Shao and Zhouxing Shi and Jinfeng Yi and Pin-Yu Chen and Cho-Jui Hsieh},
      year={2022},
      eprint={2103.15670},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.15670}, 
}

@article{Shah2024,
  author = {Syed Abdullah Shah and Imran Taj and Syed Muhammad Usman and Syed Nehal Hassan Shah and Ali Shariq Imran and Shehzad Khalid},
  title = {A hybrid approach of vision transformers and CNNs for detection of ulcerative colitis},
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {24771},
  year = {2024},
  doi = {10.1038/s41598-024-75901-4},
  url = {https://doi.org/10.1038/s41598-024-75901-4},
  abstract = {Ulcerative Colitis is an Inflammatory Bowel disease caused by a variety of factors that lead to a serious impact on the quality of life of the patients if left untreated. Due to complexities in the identification procedures of this disease, the treatment timeline and quality can be severely affected, leading to further consequences for the sufferer. The difficulties in identification are due to high patients to healthcare professionals ratio. Researchers have proposed variety of machine/deep learning methods for automated detection of ulcerative colitis, however, several challenges exists including class imbalance problem, comprehensive feature extraction and accurate classification. We propose a novel method for accurate detection of ulcerative colitis with augmentation techniques to overcome class imbalance issue, a comprehensive feature vector extraction using custom architecture of Vision Transformer (ViT) and accurate classification using customized Convolutional Neural Network (CNN). We used the TMC-UCM and LIMUC datasets in this research for training and testing of proposed method and achieved accuracy of 90% with AUC-ROC scores of 0.91, 0.81, 0.94, and 0.94 for the endoscopic classes of Mayo 0, Mayo 1, Mayo 2, and Mayo 3 respectively. We have compared the proposed method with existing state of the art methods and conclude that the proposed method outperforms the existing methods.},
  issn = {2045-2322}
}

@Article{app13095521,
AUTHOR = {Maurício, José and Domingues, Inês and Bernardino, Jorge},
TITLE = {Comparing Vision Transformers and Convolutional Neural Networks for Image Classification: A Literature Review},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {9},
ARTICLE-NUMBER = {5521},
URL = {https://www.mdpi.com/2076-3417/13/9/5521},
ISSN = {2076-3417},
ABSTRACT = {Transformers are models that implement a mechanism of self-attention, individually weighting the importance of each part of the input data. Their use in image classification tasks is still somewhat limited since researchers have so far chosen Convolutional Neural Networks for image classification and transformers were more targeted to Natural Language Processing (NLP) tasks. Therefore, this paper presents a literature review that shows the differences between Vision Transformers (ViT) and Convolutional Neural Networks. The state of the art that used the two architectures for image classification was reviewed and an attempt was made to understand what factors may influence the performance of the two deep learning architectures based on the datasets used, image size, number of target classes (for the classification problems), hardware, and evaluated architectures and top results. The objective of this work is to identify which of the architectures is the best for image classification and under what conditions. This paper also describes the importance of the Multi-Head Attention mechanism for improving the performance of ViT in image classification.},
DOI = {10.3390/app13095521}
}

@misc{wu2021cvtintroducingconvolutionsvision,
      title={CvT: Introducing Convolutions to Vision Transformers}, 
      author={Haiping Wu and Bin Xiao and Noel Codella and Mengchen Liu and Xiyang Dai and Lu Yuan and Lei Zhang},
      year={2021},
      eprint={2103.15808},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.15808}, 
}

@misc{liu2021swintransformerhierarchicalvision,
      title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, 
      author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
      year={2021},
      eprint={2103.14030},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.14030}, 
}

@misc{Midha2024,
  author = {Gaurav Midha},
  title = {Red Hat OpenShift AI and machine learning operations},
  year = {2024},
  month = {Aug},
  day = {6},
  url = {https://developers.redhat.com/articles/2024/08/06/red-hat-openshift-ai-and-machine-learning-operations},
  note = {Accessed: 2025-05-11},
  keywords = {Artificial intelligence, Automation and management, Containers, Kubernetes, Python, Red Hat OpenShift AI}
}

@misc{RedHat2023,
  author = {Red Hat},
  title = {Red Hat OpenShift Container Platform datasheet},
  year = {2023},
  month = {Jul},
  day = {5},
  url = {https://www.redhat.com/en/resources/openshift-container-platform-datasheet},
  note = {Accessed: 2025-05-11}
}

@misc{vincent_pytorch_lr_finder,
  author = {David Vincent},
  title = {pytorch-lr-finder},
  year = {n.d.},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/davidtvs/pytorch-lr-finder}},
  note = {Accessed: 2025-05-11}
}

@misc{yassin2024adam,
  author       = {Ahmed Yassin},
  title        = {Adam vs. AdamW: Understanding Weight Decay and Its Impact on Model Performance},
  year         = {2024},
  month        = {November},
  day          = {8},
  url          = {https://yassin01.medium.com/adam-vs-adamw-understanding-weight-decay-and-its-impact-on-model-performance-b7414f0af8a1},
  note         = {Accessed: 2025-05-11}
}
